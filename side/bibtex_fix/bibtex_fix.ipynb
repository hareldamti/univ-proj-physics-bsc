{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c190ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import subprocess\n",
    "from difflib import SequenceMatcher\n",
    "from urllib.parse import urljoin\n",
    "import importlib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import bibtexparser\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b26712c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Dav17  --  Probability and Braiding Statistics in Majorana Nanowires\n",
      "  Replaced by Crossref result (crossref doi 10.1103/physrevb.95.155451 (score=1.00)).\n",
      "Processing: jas24  --  Non-Abelian statistics and topological quantum information processing in 1D wire networks\n",
      "  Replaced by Crossref result (crossref doi 10.1038/nphys1915 (score=1.00)).\n",
      "Processing: kit00  --  Unpaired Majorana fermions in quantum wires\n",
      "  Replaced by Crossref result (crossref doi 10.1070/1063-7869/44/10s/s29 (score=1.00)).\n",
      "Processing: cas18  --  Majorana Braiding Dynamics on Nanowires\n",
      "  Replaced by Crossref result (crossref doi 10.1103/physrevb.91.174305 (score=0.97)).\n",
      "Processing: cwj20  --  Search for non-Abelian Majorana braiding statistics in superconductors\n",
      "  Replaced by Crossref result (crossref doi 10.21468/scipostphyslectnotes.15 (score=1.00)).\n",
      "Processing: steven21  --  Topological Quantum: Lecture Notes\n",
      "  Replaced by Crossref result (crossref doi 10.1088/2053-2563/aaf3a3 (score=0.66)).\n",
      "Processing: Che08  --  Non-Abelian Anyons and Topological Quantum Computation\n",
      "  Replaced by Crossref result (crossref doi 10.1103/revmodphys.80.1083 (score=1.00)).\n",
      "Processing: xav20  --  Entanglement and boundary entropy in quantum spin chains with arbitrary direction of the boundary magnetic fields\n",
      "  Replaced by Crossref result (crossref doi 10.1103/physrevb.101.235127 (score=1.00)).\n",
      "Processing: Gros19  --  Dynamically Induced Topology and Quantum Monodromies in a Proximity Quenched\n",
      "Gapless Wire\n",
      "  Replaced by Crossref result (crossref doi 10.1103/physrevb.102.125142 (score=1.00)).\n",
      "Processing: Adr15  --  Quantum Computing with Parafermions\n",
      "  Replaced by Crossref result (crossref doi 10.1103/physrevb.93.125105 (score=1.00)).\n",
      "Processing: jas15  --  Topological phases with parafermions: theory and blueprints\n",
      "  Replaced by Crossref result (crossref doi 10.1146/annurev-conmatphys-031115-011336 (score=1.00)).\n",
      "Processing: Mic05  --  Towards Universal Topological Quantum Computation in the $\\nu$ = 5/2 Fractional Quantum Hall State\n",
      "  Replaced by Crossref result (crossref doi 10.1007/978-3-319-50255-7_5 (score=0.76)).\n",
      "Processing: Dav12  --  Exotic non-Abelian anyons from conventional fractional quantum Hall states\n",
      "  Replaced by Crossref result (crossref doi 10.1038/ncomms2340 (score=1.00)).\n",
      "Processing: sur15  --  Quench dynamics and parity blocking in Majorana wires\n",
      "  Replaced by Crossref result (crossref doi 10.1088/1367-2630/17/5/053036 (score=1.00)).\n",
      "Processing: shr14  --  Loschmidt echo and dynamical fidelity in periodically driven quantum systems\n",
      "  Replaced by Crossref result (crossref doi 10.1209/0295-5075/106/67003 (score=1.00)).\n",
      "Processing: kel18  --  Topological Blocking in Quantum Quench Dynamics\n",
      "  Replaced by Crossref result (crossref doi 10.1103/physrevb.89.235130 (score=1.00)).\n",
      "Processing: Ing02  --  Calculation of reduced density matrices from correlation functions\n",
      "  Replaced by Crossref result (crossref doi 10.1088/0305-4470/36/14/101 (score=1.00)).\n",
      "Processing: Mar12  --  Introduction to topological superconductivity and\n",
      "Majorana fermions\n",
      "  Replaced by Crossref result (crossref doi 10.1088/0268-1242/27/12/124003 (score=1.00)).\n",
      "Processing: Kit10  --  Topological phases of fermions in one dimension\n",
      "  Replaced by Crossref result (crossref doi 10.1103/physrevb.83.075103 (score=1.00)).\n",
      "Processing: projRepo  --  Github Repo: univ-proj-physics-bsc\n",
      "  Kept original entry (no match).\n",
      "Processing: simuQ  --  SimuQ: A Framework for Programming Quantum\n",
      "Hamiltonian Simulation with Analog Compilation\n",
      "  Replaced by Crossref result (crossref doi 10.1145/3632923 (score=1.00)).\n",
      "\n",
      "Wrote updated entries to references.bib\n",
      "\n",
      "Summary (converted entries):\n",
      "  Dav17: OK (crossref doi 10.1103/physrevb.95.155451 (score=1.00))\n",
      "  jas24: OK (crossref doi 10.1038/nphys1915 (score=1.00))\n",
      "  kit00: OK (crossref doi 10.1070/1063-7869/44/10s/s29 (score=1.00))\n",
      "  cas18: OK (crossref doi 10.1103/physrevb.91.174305 (score=0.97))\n",
      "  cwj20: OK (crossref doi 10.21468/scipostphyslectnotes.15 (score=1.00))\n",
      "  steven21: OK (crossref doi 10.1088/2053-2563/aaf3a3 (score=0.66))\n",
      "  Che08: OK (crossref doi 10.1103/revmodphys.80.1083 (score=1.00))\n",
      "  xav20: OK (crossref doi 10.1103/physrevb.101.235127 (score=1.00))\n",
      "  Gros19: OK (crossref doi 10.1103/physrevb.102.125142 (score=1.00))\n",
      "  Adr15: OK (crossref doi 10.1103/physrevb.93.125105 (score=1.00))\n",
      "  jas15: OK (crossref doi 10.1146/annurev-conmatphys-031115-011336 (score=1.00))\n",
      "  Mic05: OK (crossref doi 10.1007/978-3-319-50255-7_5 (score=0.76))\n",
      "  Dav12: OK (crossref doi 10.1038/ncomms2340 (score=1.00))\n",
      "  sur15: OK (crossref doi 10.1088/1367-2630/17/5/053036 (score=1.00))\n",
      "  shr14: OK (crossref doi 10.1209/0295-5075/106/67003 (score=1.00))\n",
      "  kel18: OK (crossref doi 10.1103/physrevb.89.235130 (score=1.00))\n",
      "  Ing02: OK (crossref doi 10.1088/0305-4470/36/14/101 (score=1.00))\n",
      "  Mar12: OK (crossref doi 10.1088/0268-1242/27/12/124003 (score=1.00))\n",
      "  Kit10: OK (crossref doi 10.1103/physrevb.83.075103 (score=1.00))\n",
      "  projRepo: KEPT (no match (scholar: no scholar bibtex link found; crossref: no crossref match))\n",
      "  simuQ: OK (crossref doi 10.1145/3632923 (score=1.00))\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "update_references.py\n",
    "\n",
    "Read references.bib in the current folder, try to obtain a BibTeX entry\n",
    "from Google Scholar for each entry (fallback to Crossref if Scholar fails),\n",
    "and overwrite references.bib keeping the original entry if no match is found.\n",
    "\n",
    "Prints which conversions worked.\n",
    "\n",
    "Usage: run this cell / run the script in the same folder as references.bib.\n",
    "\"\"\"\n",
    "\n",
    "# Ensure required packages are installed\n",
    "def ensure_packages(mapping):\n",
    "    missing = []\n",
    "    for import_name, pip_name in mapping.items():\n",
    "        try:\n",
    "            importlib.import_module(import_name)\n",
    "        except ImportError:\n",
    "            missing.append(pip_name)\n",
    "    if missing:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *missing])\n",
    "\n",
    "ensure_packages({\n",
    "    \"requests\": \"requests\",\n",
    "    \"bs4\": \"beautifulsoup4\",\n",
    "    \"bibtexparser\": \"bibtexparser\"\n",
    "})\n",
    "\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "                  \"(KHTML, like Gecko) Chrome/115.0 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "}\n",
    "\n",
    "\n",
    "def clean_title(t):\n",
    "    if not t:\n",
    "        return \"\"\n",
    "    t = re.sub(r'[\\{\\}]', '', t)  # remove bib braces\n",
    "    t = re.sub(r'\\s+', ' ', t).strip()\n",
    "    try:\n",
    "        t = unicodedata.normalize('NFKD', t)\n",
    "    except Exception:\n",
    "        pass\n",
    "    t = t.lower()\n",
    "    t = re.sub(r'[^a-z0-9\\s]', ' ', t)\n",
    "    t = re.sub(r'\\s+', ' ', t).strip()\n",
    "    return t\n",
    "\n",
    "\n",
    "def search_google_scholar(title, timeout=15, max_candidates=5):\n",
    "    \"\"\"Try to find a BibTeX on Google Scholar for `title`.\n",
    "    Returns (bibtex_text or None, reason_string).\n",
    "    \"\"\"\n",
    "    url = \"https://scholar.google.com/scholar\"\n",
    "    params = {\"q\": title}\n",
    "    try:\n",
    "        resp = requests.get(url, params=params, headers=HEADERS, timeout=timeout)\n",
    "    except Exception as e:\n",
    "        return None, f\"scholar HTTP error: {e}\"\n",
    "    if resp.status_code != 200:\n",
    "        return None, f\"scholar HTTP status {resp.status_code}\"\n",
    "\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    results = soup.find_all(\"div\", class_=\"gs_ri\")\n",
    "    best = None\n",
    "    best_score = 0.0\n",
    "    # Iterate results and look for /scholar.bib href inside each result.\n",
    "    for res in results[:max_candidates]:\n",
    "        # Extract title\n",
    "        title_tag = res.find(\"h3\", class_=\"gs_rt\")\n",
    "        if title_tag is None:\n",
    "            title_tag = res.find(\"h3\")\n",
    "        result_title = title_tag.get_text(\" \", strip=True) if title_tag else \"\"\n",
    "        score = SequenceMatcher(None, clean_title(result_title), clean_title(title)).ratio()\n",
    "        # Try to find a BibTeX download link inside the result\n",
    "        bib_link = None\n",
    "        # direct link with href containing scholar.bib\n",
    "        for a in res.find_all(\"a\", href=True):\n",
    "            if \"scholar.bib\" in a[\"href\"] or \"scholar.bib\" in a.get_text().lower():\n",
    "                bib_link = a\n",
    "                break\n",
    "        # some pages include a \"BibTeX\" anchor text (in a hidden div)\n",
    "        if not bib_link:\n",
    "            for a in res.find_all(\"a\"):\n",
    "                if a.get_text() and \"bibtex\" in a.get_text().lower():\n",
    "                    bib_link = a\n",
    "                    break\n",
    "        if bib_link and score > best_score:\n",
    "            best_score = score\n",
    "            best = (bib_link, result_title, score)\n",
    "\n",
    "    # fallback: search entire page for any anchor with scholar.bib and find nearest title\n",
    "    if not best:\n",
    "        links = soup.find_all(\"a\", href=True)\n",
    "        candidates = []\n",
    "        for a in links:\n",
    "            if \"scholar.bib\" in a[\"href\"] or (\"bibtex\" in a.get_text().lower()):\n",
    "                # try to find closest preceding h3 or div.gs_ri\n",
    "                parent = a\n",
    "                candidate_title = None\n",
    "                for _ in range(6):\n",
    "                    parent = parent.parent\n",
    "                    if parent is None:\n",
    "                        break\n",
    "                    h = parent.find(\"h3\")\n",
    "                    if h:\n",
    "                        candidate_title = h.get_text(\" \", strip=True)\n",
    "                        break\n",
    "                if not candidate_title:\n",
    "                    # pick any nearby h3 in soup\n",
    "                    h = soup.find(\"h3\")\n",
    "                    candidate_title = h.get_text(\" \", strip=True) if h else \"\"\n",
    "                score = SequenceMatcher(None, clean_title(candidate_title), clean_title(title)).ratio()\n",
    "                candidates.append((a, candidate_title, score))\n",
    "        if candidates:\n",
    "            candidates.sort(key=lambda x: x[2], reverse=True)\n",
    "            a, candidate_title, score = candidates[0]\n",
    "            if score > 0:\n",
    "                best = (a, candidate_title, score)\n",
    "                best_score = score\n",
    "\n",
    "    if best:\n",
    "        a, matched_title, score = best\n",
    "        href = a.get(\"href\", \"\")\n",
    "        bib_url = urljoin(\"https://scholar.google.com\", href)\n",
    "        try:\n",
    "            bib_resp = requests.get(bib_url, headers=HEADERS, timeout=timeout)\n",
    "            if bib_resp.status_code == 200 and \"@\" in bib_resp.text:\n",
    "                return bib_resp.text, f\"scholar (score={score:.2f})\"\n",
    "            else:\n",
    "                return None, f\"scholar returned non-bibtex (status {bib_resp.status_code})\"\n",
    "        except Exception as e:\n",
    "            return None, f\"scholar fetch error: {e}\"\n",
    "    return None, \"no scholar bibtex link found\"\n",
    "\n",
    "\n",
    "def fetch_bib_crossref(title, timeout=15, rows=5):\n",
    "    \"\"\"Fallback: use Crossref to find DOI and request BibTeX via doi.org.\"\"\"\n",
    "    api = \"https://api.crossref.org/works\"\n",
    "    params = {\"query.title\": title, \"rows\": rows}\n",
    "    try:\n",
    "        r = requests.get(api, params=params, headers=HEADERS, timeout=timeout)\n",
    "    except Exception as e:\n",
    "        return None, f\"crossref HTTP error: {e}\"\n",
    "    if r.status_code != 200:\n",
    "        return None, f\"crossref HTTP status {r.status_code}\"\n",
    "    try:\n",
    "        J = r.json()\n",
    "    except Exception as e:\n",
    "        return None, f\"crossref JSON parse error: {e}\"\n",
    "    items = J.get(\"message\", {}).get(\"items\", [])\n",
    "    best_item = None\n",
    "    best_score = 0.0\n",
    "    for it in items:\n",
    "        cand_title = \"\"\n",
    "        if \"title\" in it and isinstance(it[\"title\"], list) and it[\"title\"]:\n",
    "            cand_title = it[\"title\"][0]\n",
    "        score = SequenceMatcher(None, clean_title(cand_title), clean_title(title)).ratio()\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_item = it\n",
    "    if best_item and best_score >= 0.55 and \"DOI\" in best_item:\n",
    "        doi = best_item[\"DOI\"]\n",
    "        doi_url = \"https://doi.org/\" + doi\n",
    "        headers = HEADERS.copy()\n",
    "        headers[\"Accept\"] = \"application/x-bibtex; charset=utf-8\"\n",
    "        try:\n",
    "            r2 = requests.get(doi_url, headers=headers, timeout=timeout)\n",
    "        except Exception as e:\n",
    "            return None, f\"doi.org fetch error: {e}\"\n",
    "        if r2.status_code == 200 and \"@\" in r2.text:\n",
    "            return r2.text, f\"crossref doi {doi} (score={best_score:.2f})\"\n",
    "        return None, f\"doi.org returned non-bibtex (status {r2.status_code})\"\n",
    "    return None, \"no crossref match\"\n",
    "\n",
    "\n",
    "def parse_bibtex_string(bibtex_text):\n",
    "    try:\n",
    "        db = bibtexparser.loads(bibtex_text)\n",
    "        if db.entries:\n",
    "            return db.entries[0]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "\n",
    "def main():\n",
    "    infile = \"references.bib\"\n",
    "    if not os.path.exists(infile):\n",
    "        print(\"references.bib not found in current folder.\")\n",
    "        return\n",
    "\n",
    "    with open(infile, \"r\", encoding=\"utf-8\") as f:\n",
    "        original_text = f.read()\n",
    "\n",
    "    try:\n",
    "        orig_db = bibtexparser.loads(original_text)\n",
    "        orig_entries = orig_db.entries\n",
    "    except Exception:\n",
    "        # fallback: try using bibtexparser directly from file\n",
    "        parser = bibtexparser.bparser.BibTexParser(common_strings=True)\n",
    "        with open(infile, \"r\", encoding=\"utf-8\") as f:\n",
    "            orig_db = bibtexparser.load(f, parser=parser)\n",
    "            orig_entries = orig_db.entries\n",
    "\n",
    "    new_entries = []\n",
    "    conversions = []  # list of tuples: (orig_key, success_bool, reason)\n",
    "    for entry in orig_entries:\n",
    "        key = entry.get(\"ID\") or entry.get(\"key\") or \"<no-id>\"\n",
    "        title_field = entry.get(\"title\", \"\")\n",
    "        title_clean = title_field.strip()\n",
    "        # strip surrounding braces often found in bib titles\n",
    "        title_clean = re.sub(r'^\\{(.*)\\}$', r'\\1', title_clean)\n",
    "        print(f\"Processing: {key}  --  {title_clean}\")\n",
    "        # try Google Scholar\n",
    "        scholar_bib, scholar_reason = search_google_scholar(title_clean)\n",
    "        if scholar_bib:\n",
    "            parsed = parse_bibtex_string(scholar_bib)\n",
    "            if parsed:\n",
    "                # preserve original key (ID) to avoid breaking references\n",
    "                parsed[\"ID\"] = key\n",
    "                new_entries.append(parsed)\n",
    "                conversions.append((key, True, scholar_reason))\n",
    "                print(f\"  Replaced by Google Scholar result ({scholar_reason}).\")\n",
    "                # small delay\n",
    "                time.sleep(random.uniform(1.2, 2.5))\n",
    "                continue\n",
    "        # fallback Crossref\n",
    "        cross_bib, cross_reason = fetch_bib_crossref(title_clean)\n",
    "        if cross_bib:\n",
    "            parsed = parse_bibtex_string(cross_bib)\n",
    "            if parsed:\n",
    "                parsed[\"ID\"] = key\n",
    "                new_entries.append(parsed)\n",
    "                conversions.append((key, True, cross_reason))\n",
    "                print(f\"  Replaced by Crossref result ({cross_reason}).\")\n",
    "                time.sleep(random.uniform(1.2, 2.5))\n",
    "                continue\n",
    "        # if both fail, keep original\n",
    "        new_entries.append(entry)\n",
    "        conversions.append((key, False, f\"no match (scholar: {scholar_reason}; crossref: {cross_reason})\"))\n",
    "        print(f\"  Kept original entry (no match).\")\n",
    "        time.sleep(random.uniform(1.2, 2.5))\n",
    "\n",
    "    # write back to references.bib\n",
    "    out_db = bibtexparser.bibdatabase.BibDatabase()\n",
    "    out_db.entries = new_entries\n",
    "    writer = bibtexparser.bwriter.BibTexWriter()\n",
    "    # prefer stable formatting\n",
    "    writer.order_entries_by = None\n",
    "    writer.indent = \"  \"\n",
    "    try:\n",
    "        with open(infile, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(writer.write(out_db))\n",
    "        print(\"\\nWrote updated entries to references.bib\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to write {infile}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Print summary\n",
    "    print(\"\\nSummary (converted entries):\")\n",
    "    for key, ok, reason in conversions:\n",
    "        status = \"OK\" if ok else \"KEPT\"\n",
    "        print(f\"  {key}: {status} ({reason})\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
